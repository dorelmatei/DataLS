BIG DATA PLATFORM VISION


==========================================================================================================
BUSINESS REQUIREMENTS:

- many companies migrate their solutions to big data technologies

1.Integration with data providers (Facebook, Salesforce, S3)
2.Integration with data consumers (Netezza)
3.Ability to build new applications on top of this platform
4.Ability to integrate with existing applications as data producers, data consumers 
5.Provide a rich inventory of data services 
6.Provide a mechanism to orchestrate/combine services for different business pruposes
7.Provide a set of tools for data management/ platform deployment / monitoring / command line
8.Provide also scaffolding code and samples for guidance to easily build new functionalities and apps.
9.Provide full functionality  for the main data flows of an analytics application
10.Provide support for multitenancy
11.Flexibile security (DMZ, data in transit, data at rest)

WHAT ARE THE MAIN USE CASES FOR THIS PLATFORM TO BECOME REALLY USEFULL ?

- Migration from data center to cloud  
- Standardization of services/applications/APIs
- Technologies consolidation
- IT efficiency

=========================================================================================================
TECHNICAL REQUIREMENTS:

1.Provide a strong architectural foundation based on principles and patterns
2.Provide a set of foundation concepts and objects 
3.Provide clean and well documented APIs
4.Leverage mature big data open source technologies : Hadoop and Riak
5.Lightweight, no heavy technologies or frameworks
6.Non invasive
7.On demand : attach/detach according to clients needs
8.Leverage cloud infrastructure services by virtualization (Amazon EC2, S3, MR, RDS)
9.Expose it as a SaaS
10.Component should be able to run standalone and in application servers (easy to integrate in other runtime environments)

- SDK on top of platform
- Sample apps
11.POJO based

=========================================================================================================
COMMON SERVICES :

Scheduling Service

User Management Service
Time Service
Marshalling Service
Exception/Error Handling Service
Orchestration/Workflow Service
Idempotency service
Feature based configuration service : switch on/ switch off
WatchDog Service - threads, resources
Request Acceptor Proxy
Registry service 
Identity Service (Account management)
Authentication Service
Authorization Service (OAuth)


=========================================================================================================
DATA SERVICES :

Connector (Connection management)
Extractor (Extracts data from diferent data providers)
Partitionner (Splits a data set into many data sets based on a given strategy)
Aggregator (Gathers many data sets into one data set based on a given strategy)
Accessor (Reads data fom a "data source")
MetaData Accessor (reads meta data, descriptions about data)
Mutator (Modifies data into a "data source")
Transformer (Transforms data from one format into another format - not information lost)
Converter (Converts a data type object into another object of different type - lost information possible)
Carrier (Transports data for source to destination)
Loader (Loads data into a repository)
Cleanser (Cleans data from a data source base on a strategy)
Validator (Decides if a data item is valid or not)
Augmenter (Adds more information to an exisitng data set)
Tagger (Puts a tag/label on a data element, or assign a data item to a name space)
Publisher (Publishes a data set to an external source)
REST API integration
Relationship Manager (Establishes relations between data elements)
Document Manager
Compressor (Compress/ Decompresses data sets base on a given compression algorithm)
Replicator (Copies a data set from one location into another location of the same data source type)
Streaming
Indexer
Formatter (rich formatting of content)

Classification service based on Mahout
Service registry based / using Zookeeper
Load balancer proxy : round robin/other pluggable strategy service
Translation service
Currency service
Google map/ Location service
TimeProvider
Similarity service
Calculator service
Locking (token based) service for mutual exclusion
E-payment service
Lazy processing





=========================================================================================================
ANALYTICS SERVICES :

Search/Query service
Data Mining
Reporting
Dashboards


=========================================================================================================
VISUALIZATION SERVICES :
Chart Viz
Table Viz
Graph Viz



=========================================================================================================
OPERATIONS SERVICES

JMX integration
Log Aggregator
Configurator service
Monitoring service
Watch dog

=========================================================================================================
SECURITY SERVICES

Authentication Service
Authorization Service
Encryption service
Hashing Service




=========================================================================================================
CONCEPTS :

Bridge
Pipe
Flow
Process
Data Service Object (DSO)
Data Provider
Context
Event
State
StateMachine
Request
Response
Identifiable




=========================================================================================================
BUILDING BLOCKS :

Runtime Building Block : 
- service location , injection
- design by contract
- thread pool/fork execution / map-reduce
- extension points
- client-service interactor
- services and modules management (start/stop, init/destroy)

Platform Building Block :
- Data Element
- DSO
- Entity
- Bean
- Resource
- Bridge
- Pipe
- Flow

Acquisition Building Block
- Connectors to data providers


Master Repository Building Block
- Data organizer / structurer

========================================================================================================
TECHNOLOGIES :

Hadoop ecosystem
HDFS
Riak
Netezza (Partnership ???)

=========================================================================================================
BIG DATA RELATED PATTERNS/PRINCIPLES :

1.Data Locality

2.Pipes

3.Batch processing

4.In memory data / Caching

5.Map/Reduce

6.Resource management : leasing, pools, 

7.Idempotency 

8.Best effort

9.Restart

10.Resume

11.Fork / Join

=========================================================================================================
HORIZONTALS :

Runtime
- execution : fork join, JVM
- extension
- contracts
- configuration
- commands
- resource managers (pools)
- DI
- dependency management
- memory management (watch dogs)
- space management (watch dogs)
- JVM and arguments
- execution environment
- runtime exceptions
- versionning
- state machines


Domain
- entities
- value objects
- services
- events
- aggregates

Basic Services :
- common services
- data services


Integration
- workflow
- orchestration
- messaging
- bridge


HelperService
- idempotency service


DataServices



VERTICALS :


Acquisition 

Master Repository

Analytics



SDK :
- documentation of APIs
- tools (shell, import/export)
- samples
- scafolding code


==================================================================================

 FOUNDATION FOR JAVA (TM)

==================================================================================

1.Project structure:
Version Control : git (branching strategy)
Build tool :  mvn (structure)
Continuous integration: Hudson (nighlty + daily)
Static Analysis : Sonar (guidelines)
Dependency Injection : Google Guice
License :  LGPL, Apache 2, TPG 


2.Documentation 
3.Tools : Eclipse, Intellij, JProfiler, JVisualVM, 
4.Templates : java conventions, knowledge transfer 
5.APIs from 3PILLAR REPOSITORY (NEXUS)
- platform



6.REQUIREMENTS, ARCHITECTURE, DESIGN, Code REVIEW, 
7.Guidelines



 